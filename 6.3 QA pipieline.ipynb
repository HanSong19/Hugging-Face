{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAcyDBYAeybtekXQ4fgw+q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanSong19/Hugging-Face/blob/main/6.3%20QA%20pipieline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer-Question/Answering Pipeline"
      ],
      "metadata": {
        "id": "M_sbqL3ZZHY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8tEdgGpZEBd",
        "outputId": "73291c41-abff-4845-ef50-f016de60b3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Using cached datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "Collecting evaluate\n",
            "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "Collecting transformers[sentencepiece]\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece])\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, xxhash, dill, responses, multiprocess, huggingface-hub, transformers, datasets, evaluate\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 evaluate-0.4.0 huggingface-hub-0.16.4 multiprocess-0.70.15 responses-0.18.0 safetensors-0.3.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiRQR_C9ZyFU",
        "outputId": "914638c0-b25f-4ba3-f4df-95c90296fe21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Which deep learning libraries back ðŸ¤— Transformers?\"\n",
        "\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfBtY7sTaI-5",
        "outputId": "3f5943c9-4a51-4068-d09f-f125e5c8c116"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9802603125572205,\n",
              " 'start': 78,\n",
              " 'end': 106,\n",
              " 'answer': 'Jax, PyTorch, and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "long_context = \"\"\"\n",
        "ðŸ¤— Transformers: State of the Art NLP\n",
        "\n",
        "ðŸ¤— Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
        "question answering, summarization, translation, text generation and more in over 100 languages.\n",
        "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
        "\n",
        "ðŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
        "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
        "can be modified to enable quick research experiments.\n",
        "\n",
        "Why should I use transformers?\n",
        "\n",
        "1. Easy-to-use state-of-the-art models:\n",
        "  - High performance on NLU and NLG tasks.\n",
        "  - Low barrier to entry for educators and practitioners.\n",
        "  - Few user-facing abstractions with just three classes to learn.\n",
        "  - A unified API for using all our pretrained models.\n",
        "  - Lower compute costs, smaller carbon footprint:\n",
        "\n",
        "2. Researchers can share trained models instead of always retraining.\n",
        "  - Practitioners can reduce compute time and production costs.\n",
        "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
        "\n",
        "3. Choose the right framework for every part of a model's lifetime:\n",
        "  - Train state-of-the-art models in 3 lines of code.\n",
        "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
        "  - Seamlessly pick the right framework for training, evaluation and production.\n",
        "\n",
        "4. Easily customize a model or an example to your needs:\n",
        "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
        "  - Model internals are exposed as consistently as possible.\n",
        "  - Model files can be used independently of the library for quick experiments.\n",
        "\n",
        "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "question_answerer(question=question, context = long_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jheH9p61anhj",
        "outputId": "1c5a757d-cfd0-427e-cbfe-71baaaa68bb4"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9714871048927307,\n",
              " 'start': 1892,\n",
              " 'end': 1919,\n",
              " 'answer': 'Jax, PyTorch and TensorFlow'}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model= AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "inputs=tokenizer(question, context, return_tensors=\"pt\")\n",
        "output=model(**inputs)"
      ],
      "metadata": {
        "id": "qz1JHQN8b18A"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits=output.start_logits\n",
        "end_logits=output.end_logits\n",
        "\n",
        "print(start_logits, end_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjAecckKhySO",
        "outputId": "14a05c67-9cbb-471f-a6cd-909855df1e39"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.4952, -6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368,\n",
            "         -5.9199, -5.4193, -1.5920, -1.0857, -5.0981, -2.9331, -3.4070,  2.2467,\n",
            "          5.1563, -1.3602, -2.2209, -0.9686, -4.8112, -2.2527,  1.4383, 10.1211,\n",
            "         -1.5311,  2.2685, -1.8951, -2.2108, -4.2142, -2.5571, -2.3252, -2.6046,\n",
            "          1.7047, -1.9867, -1.7211, -0.5415, -2.0239, -4.4246, -5.1012, -4.4966,\n",
            "         -7.8940, -6.7200, -4.6759, -6.3278, -4.8339, -5.1839, -3.3724, -7.4120,\n",
            "         -8.1542, -4.4871, -7.4659, -4.3293, -4.2293, -3.1903, -7.9467, -5.2665,\n",
            "         -7.5902, -5.0570, -7.4476, -7.9083, -6.5951, -7.4061, -8.8821, -7.6749,\n",
            "         -6.9879, -7.0466, -5.4193]], grad_fn=<CloneBackward0>) tensor([[-2.3958e+00, -7.0978e+00, -7.0745e+00, -6.3676e+00, -5.9532e+00,\n",
            "         -7.9585e+00, -7.1869e+00, -3.6494e+00, -6.9677e+00, -5.1421e+00,\n",
            "         -3.1757e+00, -1.1649e+00, -7.0748e+00, -5.2875e+00, -6.8611e+00,\n",
            "         -5.1769e+00,  3.7892e+00, -4.4408e+00, -7.6687e-01, -3.9180e+00,\n",
            "         -2.1634e+00,  1.8116e+00, -1.4678e+00,  2.0508e+00,  1.5404e-03,\n",
            "         -1.5531e+00, -6.9470e-01, -1.3466e+00, -1.6879e+00,  4.0826e+00,\n",
            "          1.1467e+00, -3.7881e-01,  6.0774e-01,  1.2281e+00,  5.8202e-01,\n",
            "          1.0657e+01,  5.8794e+00, -5.7342e+00, -7.0719e+00, -6.8077e+00,\n",
            "         -7.1513e+00, -5.3228e+00, -3.4305e+00, -4.2575e+00,  2.2268e+00,\n",
            "         -4.1297e-01, -6.8944e+00, -7.9381e+00, -8.3298e+00, -5.6078e+00,\n",
            "         -8.9589e+00, -5.5772e+00, -5.7309e+00, -1.9592e+00, -7.8078e+00,\n",
            "         -2.3823e+00, -7.2457e+00, -6.1642e+00, -4.2830e+00, -8.0948e+00,\n",
            "         -8.0364e+00, -4.5566e+00, -7.6585e+00, -7.3241e+00, -2.2402e+00,\n",
            "         -1.8462e+00, -5.1421e+00]], grad_fn=<CloneBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(start_logits.shape, end_logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRmb5L8SqPIi",
        "outputId": "bf878e10-7fa4-4998-b56d-e483e5dd8d09"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 67]) torch.Size([1, 67])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sequence_ids = inputs.sequence_ids()\n",
        "mask = [i !=1 for i in sequence_ids]\n",
        "\n",
        "# Do not mask CLS token\n",
        "mask[0] = False"
      ],
      "metadata": {
        "id": "NuBpEDZijN-4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sequence_ids = inputs.sequence_ids()\n",
        "\n",
        "print(sequence_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEWSonB9oF03",
        "outputId": "fe87531c-83db-47f0-a55e-d290ae2507e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = [i !=1 for i in sequence_ids]\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F25VdgSKoPEu",
        "outputId": "f7b43075-8afd-4e91-c182-54aaa249098d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0] = False\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyrWgFGNoWQp",
        "outputId": "08178de9-c7e5-496a-d147-4fb304195a50"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.tensor(mask)\n",
        "\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq6Ogh-coa7U",
        "outputId": "2ca1f302-44c3-45d1-b8f0-d21f9a00bad9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False,  True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.tensor(mask)[None]\n",
        "\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhVJRBMMok0L",
        "outputId": "118e845c-1539-4883-8d38-74b187bb5e72"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False,  True]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-8bd0e9a597dc>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  mask = torch.tensor(mask)[None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(start_logits[mask].shape)\n",
        "print(start_logits[mask])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYusHGTCvG0a",
        "outputId": "d4ab5f06-25b4-4172-cd24-ff977cc0b71b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n",
            "tensor([-6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368, -5.9199,\n",
            "        -5.4193, -5.4193], grad_fn=<IndexBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits[mask] = -1000\n",
        "end_logits[mask]= -1000"
      ],
      "metadata": {
        "id": "IHXEmlKRpGFl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]\n",
        "print(start_probabilities, end_probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKyW-qWYqXst",
        "outputId": "08cebb2f-cf3b-4abe-ad67-f95519a233a8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.4531e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1185e-06, 1.3470e-05,\n",
            "        2.4368e-07, 2.1236e-06, 1.3220e-06, 3.7722e-04, 6.9219e-03, 1.0237e-05,\n",
            "        4.3289e-06, 1.5143e-05, 3.2463e-07, 4.1933e-06, 1.6808e-04, 9.9179e-01,\n",
            "        8.6288e-06, 3.8557e-04, 5.9956e-06, 4.3725e-06, 5.8977e-07, 3.0929e-06,\n",
            "        3.8999e-06, 2.9493e-06, 2.1940e-04, 5.4713e-06, 7.1354e-06, 2.3212e-05,\n",
            "        5.2711e-06, 4.7788e-07, 2.4291e-07, 4.4467e-07, 1.4879e-08, 4.8133e-08,\n",
            "        3.7169e-07, 7.1242e-08, 3.1735e-07, 2.2365e-07, 1.3685e-06, 2.4093e-08,\n",
            "        1.1470e-08, 4.4891e-07, 2.2828e-08, 5.2562e-07, 5.8092e-07, 1.6419e-06,\n",
            "        1.4114e-08, 2.0591e-07, 2.0161e-08, 2.5390e-07, 2.3251e-08, 1.4667e-08,\n",
            "        5.4533e-08, 2.4235e-08, 5.5390e-09, 1.8524e-08, 3.6818e-08, 3.4721e-08,\n",
            "        0.0000e+00], grad_fn=<SelectBackward0>) tensor([2.1185e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7129e-07, 7.2546e-06,\n",
            "        1.9679e-08, 1.1754e-07, 2.4366e-08, 1.3130e-07, 1.0284e-03, 2.7411e-07,\n",
            "        1.0801e-05, 4.6233e-07, 2.6730e-06, 1.4233e-04, 5.3586e-06, 1.8078e-04,\n",
            "        2.3292e-05, 4.9207e-06, 1.1610e-05, 6.0494e-06, 4.3002e-06, 1.3790e-03,\n",
            "        7.3201e-05, 1.5923e-05, 4.2704e-05, 7.9413e-05, 4.1620e-05, 9.8838e-01,\n",
            "        8.3161e-03, 7.5197e-08, 1.9735e-08, 2.5704e-08, 1.8229e-08, 1.1346e-07,\n",
            "        7.5278e-07, 3.2926e-07, 2.1558e-04, 1.5388e-05, 2.3568e-08, 8.2993e-09,\n",
            "        5.6096e-09, 8.5331e-08, 2.9904e-09, 8.7980e-08, 7.5447e-08, 3.2784e-06,\n",
            "        9.4549e-09, 2.1473e-06, 1.6586e-08, 4.8915e-08, 3.2096e-07, 7.0959e-09,\n",
            "        7.5224e-09, 2.4413e-07, 1.0978e-08, 1.5336e-08, 2.4753e-06, 3.6704e-06,\n",
            "        0.0000e+00], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = start_probabilities[:, None] * end_probabilities[:, None]"
      ],
      "metadata": {
        "id": "poYVkdoHrmgr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vngu3GLFrpQ9",
        "outputId": "882f680c-1ba4-4bee-c85d-9e7628886941"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.4340e-13],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [7.8854e-12],\n",
            "        [9.7719e-11],\n",
            "        [4.7954e-15],\n",
            "        [2.4961e-13],\n",
            "        [3.2212e-14],\n",
            "        [4.9527e-11],\n",
            "        [7.1188e-06],\n",
            "        [2.8061e-12],\n",
            "        [4.6758e-11],\n",
            "        [7.0012e-12],\n",
            "        [8.6774e-13],\n",
            "        [5.9682e-10],\n",
            "        [9.0068e-10],\n",
            "        [1.7930e-04],\n",
            "        [2.0098e-10],\n",
            "        [1.8973e-09],\n",
            "        [6.9608e-11],\n",
            "        [2.6451e-11],\n",
            "        [2.5362e-12],\n",
            "        [4.2651e-09],\n",
            "        [2.8547e-10],\n",
            "        [4.6961e-11],\n",
            "        [9.3691e-09],\n",
            "        [4.3449e-10],\n",
            "        [2.9697e-10],\n",
            "        [2.2943e-05],\n",
            "        [4.3835e-08],\n",
            "        [3.5935e-14],\n",
            "        [4.7939e-15],\n",
            "        [1.1430e-14],\n",
            "        [2.7122e-16],\n",
            "        [5.4613e-15],\n",
            "        [2.7980e-13],\n",
            "        [2.3457e-14],\n",
            "        [6.8414e-11],\n",
            "        [3.4415e-12],\n",
            "        [3.2254e-14],\n",
            "        [1.9996e-16],\n",
            "        [6.4342e-17],\n",
            "        [3.8306e-14],\n",
            "        [6.8266e-17],\n",
            "        [4.6245e-14],\n",
            "        [4.3829e-14],\n",
            "        [5.3828e-12],\n",
            "        [1.3345e-16],\n",
            "        [4.4216e-13],\n",
            "        [3.3439e-16],\n",
            "        [1.2420e-14],\n",
            "        [7.4626e-15],\n",
            "        [1.0408e-16],\n",
            "        [4.1021e-16],\n",
            "        [5.9165e-15],\n",
            "        [6.0805e-17],\n",
            "        [2.8409e-16],\n",
            "        [9.1135e-14],\n",
            "        [1.2744e-13],\n",
            "        [0.0000e+00]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = start_probabilities[:, None] * end_probabilities[None, :]\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nZKZTXVrtOn",
        "outputId": "3e3ac35f-e832-43e4-8b7e-072e1bf1c7f5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.4340e-13, 0.0000e+00, 0.0000e+00,  ..., 1.1023e-12, 1.6345e-12,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [7.8000e-14, 0.0000e+00, 0.0000e+00,  ..., 9.1135e-14, 1.3514e-13,\n",
            "         0.0000e+00],\n",
            "        [7.3557e-14, 0.0000e+00, 0.0000e+00,  ..., 8.5944e-14, 1.2744e-13,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(start_probabilities[None, :])\n",
        "print(start_probabilities[:, None])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlBRRu98tJ7R",
        "outputId": "59842afa-6b32-44de-88b0-e2c570b00265"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.4531e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1185e-06, 1.3470e-05,\n",
            "         2.4368e-07, 2.1236e-06, 1.3220e-06, 3.7722e-04, 6.9219e-03, 1.0237e-05,\n",
            "         4.3289e-06, 1.5143e-05, 3.2463e-07, 4.1933e-06, 1.6808e-04, 9.9179e-01,\n",
            "         8.6288e-06, 3.8557e-04, 5.9956e-06, 4.3725e-06, 5.8977e-07, 3.0929e-06,\n",
            "         3.8999e-06, 2.9493e-06, 2.1940e-04, 5.4713e-06, 7.1354e-06, 2.3212e-05,\n",
            "         5.2711e-06, 4.7788e-07, 2.4291e-07, 4.4467e-07, 1.4879e-08, 4.8133e-08,\n",
            "         3.7169e-07, 7.1242e-08, 3.1735e-07, 2.2365e-07, 1.3685e-06, 2.4093e-08,\n",
            "         1.1470e-08, 4.4891e-07, 2.2828e-08, 5.2562e-07, 5.8092e-07, 1.6419e-06,\n",
            "         1.4114e-08, 2.0591e-07, 2.0161e-08, 2.5390e-07, 2.3251e-08, 1.4667e-08,\n",
            "         5.4533e-08, 2.4235e-08, 5.5390e-09, 1.8524e-08, 3.6818e-08, 3.4721e-08,\n",
            "         0.0000e+00]], grad_fn=<SliceBackward0>)\n",
            "tensor([[4.4531e-07],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [8.1185e-06],\n",
            "        [1.3470e-05],\n",
            "        [2.4368e-07],\n",
            "        [2.1236e-06],\n",
            "        [1.3220e-06],\n",
            "        [3.7722e-04],\n",
            "        [6.9219e-03],\n",
            "        [1.0237e-05],\n",
            "        [4.3289e-06],\n",
            "        [1.5143e-05],\n",
            "        [3.2463e-07],\n",
            "        [4.1933e-06],\n",
            "        [1.6808e-04],\n",
            "        [9.9179e-01],\n",
            "        [8.6288e-06],\n",
            "        [3.8557e-04],\n",
            "        [5.9956e-06],\n",
            "        [4.3725e-06],\n",
            "        [5.8977e-07],\n",
            "        [3.0929e-06],\n",
            "        [3.8999e-06],\n",
            "        [2.9493e-06],\n",
            "        [2.1940e-04],\n",
            "        [5.4713e-06],\n",
            "        [7.1354e-06],\n",
            "        [2.3212e-05],\n",
            "        [5.2711e-06],\n",
            "        [4.7788e-07],\n",
            "        [2.4291e-07],\n",
            "        [4.4467e-07],\n",
            "        [1.4879e-08],\n",
            "        [4.8133e-08],\n",
            "        [3.7169e-07],\n",
            "        [7.1242e-08],\n",
            "        [3.1735e-07],\n",
            "        [2.2365e-07],\n",
            "        [1.3685e-06],\n",
            "        [2.4093e-08],\n",
            "        [1.1470e-08],\n",
            "        [4.4891e-07],\n",
            "        [2.2828e-08],\n",
            "        [5.2562e-07],\n",
            "        [5.8092e-07],\n",
            "        [1.6419e-06],\n",
            "        [1.4114e-08],\n",
            "        [2.0591e-07],\n",
            "        [2.0161e-08],\n",
            "        [2.5390e-07],\n",
            "        [2.3251e-08],\n",
            "        [1.4667e-08],\n",
            "        [5.4533e-08],\n",
            "        [2.4235e-08],\n",
            "        [5.5390e-09],\n",
            "        [1.8524e-08],\n",
            "        [3.6818e-08],\n",
            "        [3.4721e-08],\n",
            "        [0.0000e+00]], grad_fn=<UnsqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=[True,False,True]\n",
        "print(a)\n",
        "\n",
        "a=torch.tensor(a)[None]\n",
        "print(a)\n",
        "print(a[:, None])\n",
        "print(a[None, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0yAVwCQuZG6",
        "outputId": "cde41d5f-cccd-403f-fc19-eac7993616ba"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, False, True]\n",
            "tensor([[ True, False,  True]])\n",
            "tensor([[[ True, False,  True]]])\n",
            "tensor([[[ True, False,  True]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = torch.triu(scores)"
      ],
      "metadata": {
        "id": "ZYvjp7SwxjqB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fFB1MXsFsV_",
        "outputId": "28f79c8f-75c1-4fd0-e3fe-16049395db68"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.4340e-13, 0.0000e+00, 0.0000e+00,  ..., 1.1023e-12, 1.6345e-12,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1135e-14, 1.3514e-13,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.2744e-13,\n",
            "         0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00]], grad_fn=<TriuBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_index = scores.argmax().item()\n",
        "start_index = max_index // scores.shape[1]\n",
        "end_index = max_index % scores.shape[1]\n",
        "print(scores[start_index, end_index ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWb0eooiFmK9",
        "outputId": "1eebea03-05fd-4921-a114-9e9cc488220b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9803, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)\n",
        "offsets=inputs_with_offsets[\"offset_mapping\"]\n",
        "print(offsets)\n",
        "\n",
        "start_char,_ = offsets[start_index]\n",
        "_, end_char=offsets[end_index]\n",
        "answer = context[start_char:end_char]\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TWCurh4GOGJ",
        "outputId": "4b0d196d-9659-41d3-dd83-0059938891a9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1, 2), (3, 15), (16, 18), (19, 25), (26, 28), (29, 32), (33, 38), (39, 43), (44, 51), (52, 56), (57, 65), (66, 75), (76, 77), (78, 81), (81, 82), (83, 84), (84, 85), (85, 86), (86, 88), (88, 90), (90, 91), (92, 95), (96, 99), (99, 102), (102, 103), (103, 106), (107, 108), (109, 113), (114, 115), (116, 119), (119, 120), (120, 124), (125, 136), (137, 144), (145, 149), (149, 150), (151, 153), (153, 154), (154, 155), (156, 171), (172, 174), (175, 180), (181, 185), (186, 192), (193, 197), (198, 201), (202, 208), (209, 216), (217, 221), (222, 225), (226, 228), (228, 235), (236, 240), (241, 244), (245, 250), (250, 251), (0, 0)]\n",
            "Jax, PyTorch, and TensorFlow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = {\n",
        "    \"answer\": answer,\n",
        "    \"start\": start_char,\n",
        "    \"end\": end_char,\n",
        "    \"score\": scores[start_index, end_index]\n",
        "}"
      ],
      "metadata": {
        "id": "3kAJ47DMLcDq"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gbshQZ1L1sz",
        "outputId": "ce77b0f4-6a6c-42ce-8c13-8133606224fd"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': 'Jax, PyTorch, and TensorFlow', 'start': 78, 'end': 106, 'score': tensor(0.9803, grad_fn=<SelectBackward0>)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling long contexts"
      ],
      "metadata": {
        "id": "1xTGANFEMJTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(question, long_context)\n",
        "print(len(inputs[\"input_ids\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTfmECA4L43Y",
        "outputId": "ae499e92-27b1-4b85-c580-b9cfc6aceb33"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This sentence is not too long but we are going to split it anyway.\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "    sentence, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "\n",
        "for ids in inputs[\"input_ids\"]:\n",
        "  print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj8nMGyFMSNE",
        "outputId": "cdb7be20-b6b6-4c48-e1a4-b5d10df05d39"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] This sentence is not [SEP]\n",
            "[CLS] is not too long [SEP]\n",
            "[CLS] too long but we [SEP]\n",
            "[CLS] but we are going [SEP]\n",
            "[CLS] are going to split [SEP]\n",
            "[CLS] to split it anyway [SEP]\n",
            "[CLS] it anyway. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-YLX5GnPk3J",
        "outputId": "726d3b02-4134-4c40-fbf7-70f60b50265c"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "800h6ChsPoG9",
        "outputId": "9945cc11-3a79-4295-bd77-6e59045c2bf8"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"This sentence is not too long but we are going to split it anyway.\",\n",
        "    \"This sentence is shorter but will still get split.\",\n",
        "]\n",
        "\n",
        "inputs = tokenizer(\n",
        "    sentences, truncation=True, return_overflowing_tokens=True, max_length = 6, stride=2\n",
        ")\n",
        "\n",
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZLFyFALQQ07",
        "outputId": "ec47e7fe-f027-4b7f-85bd-0bfc44570f4a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    question,\n",
        "    long_context,\n",
        "    stride= 128,\n",
        "    max_length = 384,\n",
        "    padding=\"longest\",\n",
        "    truncation = \"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True\n",
        ")"
      ],
      "metadata": {
        "id": "BxJHo53sQejC"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)\n",
        "print(inputs['overflow_to_sample_mapping'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F51518nhR_Gr",
        "outputId": "c739901d-a1c8-41d5-afa9-3f6db0827503"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 5979, 1996, 3776, 9818, 1171, 100, 25267, 136, 102, 100, 25267, 131, 1426, 1104, 1103, 2051, 21239, 2101, 100, 25267, 2790, 4674, 1104, 3073, 4487, 9044, 3584, 1106, 3870, 8249, 1113, 6685, 1216, 1112, 5393, 117, 1869, 16026, 117, 2304, 10937, 117, 7584, 7317, 2734, 117, 5179, 117, 3087, 3964, 1105, 1167, 1107, 1166, 1620, 3483, 119, 2098, 6457, 1110, 1106, 1294, 5910, 118, 2652, 21239, 2101, 5477, 1106, 1329, 1111, 2490, 119, 100, 25267, 2790, 20480, 1116, 1106, 1976, 9133, 1105, 1329, 1343, 3073, 4487, 9044, 3584, 1113, 170, 1549, 3087, 117, 2503, 118, 9253, 1172, 1113, 1240, 1319, 2233, 27948, 1105, 1173, 2934, 1172, 1114, 1103, 1661, 1113, 1412, 2235, 10960, 119, 1335, 1103, 1269, 1159, 117, 1296, 185, 25669, 8613, 13196, 13682, 1126, 4220, 1110, 3106, 2484, 20717, 1673, 1105, 1169, 1129, 5847, 1106, 9396, 3613, 1844, 7857, 119, 2009, 1431, 146, 1329, 11303, 1468, 136, 122, 119, 12167, 118, 1106, 118, 1329, 1352, 118, 1104, 118, 1103, 118, 1893, 3584, 131, 118, 1693, 2099, 1113, 21239, 2591, 1105, 21239, 2349, 8249, 119, 118, 8274, 9391, 1106, 3990, 1111, 24937, 1105, 16681, 119, 118, 17751, 4795, 118, 4749, 11108, 5266, 1114, 1198, 1210, 3553, 1106, 3858, 119, 118, 138, 13943, 20480, 1111, 1606, 1155, 1412, 3073, 4487, 9044, 3584, 119, 118, 5738, 3254, 22662, 4692, 117, 2964, 6302, 2555, 10988, 131, 123, 119, 26982, 1169, 2934, 3972, 3584, 1939, 1104, 1579, 1231, 4487, 16534, 119, 118, 153, 19366, 3121, 2116, 1468, 1169, 4851, 3254, 22662, 1159, 1105, 1707, 4692, 119, 118, 2091, 10947, 1116, 1104, 4220, 1116, 1114, 1166, 1275, 117, 1288, 3073, 4487, 9044, 3584, 117, 1199, 1107, 1167, 1190, 1620, 3483, 119, 124, 119, 22964, 6787, 1103, 1268, 8297, 1111, 1451, 1226, 1104, 170, 2235, 112, 188, 7218, 131, 118, 9791, 1352, 118, 1104, 118, 1103, 118, 1893, 3584, 1107, 124, 2442, 1104, 3463, 119, 118, 15729, 170, 1423, 2235, 1206, 157, 2271, 1477, 119, 121, 120, 153, 1183, 1942, 1766, 1732, 8297, 1116, 1120, 1209, 119, 118, 3017, 1306, 8709, 3368, 1103, 1268, 8297, 1111, 2013, 117, 10540, 1105, 1707, 119, 125, 119, 142, 20158, 8156, 3708, 170, 2235, 1137, 1126, 1859, 1106, 1240, 2993, 131, 118, 1284, 2194, 5136, 1111, 1296, 4220, 1106, 23577, 1103, 2686, 1502, 1118, 1157, 1560, 5752, 119, 118, 6747, 4422, 102], [101, 5979, 1996, 3776, 9818, 1171, 100, 25267, 136, 102, 2091, 10947, 1116, 1104, 4220, 1116, 1114, 1166, 1275, 117, 1288, 3073, 4487, 9044, 3584, 117, 1199, 1107, 1167, 1190, 1620, 3483, 119, 124, 119, 22964, 6787, 1103, 1268, 8297, 1111, 1451, 1226, 1104, 170, 2235, 112, 188, 7218, 131, 118, 9791, 1352, 118, 1104, 118, 1103, 118, 1893, 3584, 1107, 124, 2442, 1104, 3463, 119, 118, 15729, 170, 1423, 2235, 1206, 157, 2271, 1477, 119, 121, 120, 153, 1183, 1942, 1766, 1732, 8297, 1116, 1120, 1209, 119, 118, 3017, 1306, 8709, 3368, 1103, 1268, 8297, 1111, 2013, 117, 10540, 1105, 1707, 119, 125, 119, 142, 20158, 8156, 3708, 170, 2235, 1137, 1126, 1859, 1106, 1240, 2993, 131, 118, 1284, 2194, 5136, 1111, 1296, 4220, 1106, 23577, 1103, 2686, 1502, 1118, 1157, 1560, 5752, 119, 118, 6747, 4422, 1116, 1132, 5490, 1112, 10887, 1112, 1936, 119, 118, 6747, 7004, 1169, 1129, 1215, 8942, 1104, 1103, 3340, 1111, 3613, 7857, 119, 100, 25267, 1110, 5534, 1118, 1103, 1210, 1211, 1927, 1996, 3776, 9818, 783, 13612, 117, 153, 1183, 1942, 1766, 1732, 1105, 5157, 21484, 2271, 6737, 783, 1114, 170, 2343, 1306, 2008, 9111, 1206, 1172, 119, 1135, 112, 188, 21546, 1106, 2669, 1240, 3584, 1114, 1141, 1196, 10745, 1172, 1111, 1107, 16792, 1114, 1103, 1168, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'offset_mapping': [[(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1, 2), (3, 15), (15, 16), (17, 22), (23, 25), (26, 29), (30, 33), (34, 36), (36, 37), (39, 40), (41, 53), (54, 62), (63, 72), (73, 75), (76, 79), (79, 82), (82, 86), (87, 93), (94, 96), (97, 104), (105, 110), (111, 113), (114, 119), (120, 124), (125, 127), (128, 142), (142, 143), (144, 155), (156, 166), (166, 167), (168, 176), (177, 186), (186, 187), (188, 191), (191, 194), (194, 201), (201, 202), (203, 214), (214, 215), (216, 220), (221, 231), (232, 235), (236, 240), (241, 243), (244, 248), (249, 252), (253, 262), (262, 263), (264, 267), (268, 271), (272, 274), (275, 277), (278, 282), (283, 290), (290, 291), (291, 295), (296, 298), (298, 299), (300, 306), (307, 309), (310, 313), (314, 317), (318, 326), (326, 327), (329, 330), (331, 343), (344, 352), (353, 356), (356, 357), (358, 360), (361, 368), (369, 377), (378, 381), (382, 385), (386, 391), (392, 395), (395, 398), (398, 402), (403, 409), (410, 412), (413, 414), (415, 420), (421, 425), (425, 426), (427, 431), (431, 432), (432, 436), (437, 441), (442, 444), (445, 449), (450, 453), (454, 458), (458, 462), (463, 466), (467, 471), (472, 477), (478, 482), (483, 487), (488, 491), (492, 501), (502, 504), (505, 508), (509, 514), (515, 518), (518, 519), (520, 522), (523, 526), (527, 531), (532, 536), (536, 537), (538, 542), (543, 544), (544, 546), (546, 549), (550, 556), (557, 565), (566, 568), (569, 581), (582, 584), (585, 590), (591, 596), (596, 599), (599, 601), (602, 605), (606, 609), (610, 612), (613, 621), (622, 624), (625, 631), (632, 637), (638, 646), (647, 658), (658, 659), (661, 664), (665, 671), (672, 673), (674, 677), (678, 687), (687, 690), (690, 691), (693, 694), (694, 695), (696, 700), (700, 701), (701, 703), (703, 704), (704, 707), (708, 713), (713, 714), (714, 716), (716, 717), (717, 720), (720, 721), (721, 724), (725, 731), (731, 732), (735, 736), (737, 741), (742, 753), (754, 756), (757, 759), (759, 760), (761, 764), (765, 767), (767, 768), (769, 774), (774, 775), (778, 779), (780, 783), (784, 791), (792, 794), (795, 800), (801, 804), (805, 814), (815, 818), (819, 832), (832, 833), (836, 837), (838, 841), (842, 846), (846, 847), (847, 853), (854, 862), (862, 866), (867, 871), (872, 876), (877, 882), (883, 890), (891, 893), (894, 899), (899, 900), (903, 904), (905, 906), (907, 914), (915, 918), (919, 922), (923, 928), (929, 932), (933, 936), (937, 940), (940, 943), (943, 947), (948, 954), (954, 955), (958, 959), (960, 965), (966, 969), (969, 973), (974, 979), (979, 980), (981, 988), (989, 995), (996, 1000), (1000, 1005), (1005, 1006), (1008, 1009), (1009, 1010), (1011, 1022), (1023, 1026), (1027, 1032), (1033, 1040), (1041, 1047), (1048, 1055), (1056, 1058), (1059, 1065), (1066, 1068), (1068, 1071), (1071, 1076), (1076, 1077), (1080, 1081), (1082, 1083), (1083, 1086), (1086, 1088), (1088, 1092), (1092, 1095), (1096, 1099), (1100, 1106), (1107, 1110), (1110, 1114), (1115, 1119), (1120, 1123), (1124, 1134), (1135, 1140), (1140, 1141), (1144, 1145), (1146, 1148), (1148, 1151), (1151, 1152), (1153, 1155), (1156, 1168), (1168, 1169), (1170, 1174), (1175, 1179), (1180, 1182), (1182, 1183), (1183, 1186), (1187, 1190), (1190, 1193), (1193, 1197), (1198, 1204), (1204, 1205), (1206, 1210), (1211, 1213), (1214, 1218), (1219, 1223), (1224, 1227), (1228, 1237), (1237, 1238), (1240, 1241), (1241, 1242), (1243, 1246), (1246, 1249), (1250, 1253), (1254, 1259), (1260, 1269), (1270, 1273), (1274, 1279), (1280, 1284), (1285, 1287), (1288, 1289), (1290, 1295), (1295, 1296), (1296, 1297), (1298, 1306), (1306, 1307), (1310, 1311), (1312, 1317), (1318, 1323), (1323, 1324), (1324, 1326), (1326, 1327), (1327, 1330), (1330, 1331), (1331, 1334), (1335, 1341), (1342, 1344), (1345, 1346), (1347, 1352), (1353, 1355), (1356, 1360), (1360, 1361), (1364, 1365), (1366, 1370), (1371, 1372), (1373, 1379), (1380, 1385), (1386, 1393), (1394, 1395), (1395, 1396), (1396, 1397), (1397, 1398), (1398, 1399), (1399, 1400), (1400, 1401), (1401, 1402), (1402, 1403), (1403, 1405), (1405, 1407), (1408, 1417), (1417, 1418), (1419, 1421), (1422, 1426), (1426, 1427), (1430, 1431), (1432, 1435), (1435, 1436), (1436, 1442), (1443, 1447), (1448, 1451), (1452, 1457), (1458, 1467), (1468, 1471), (1472, 1480), (1480, 1481), (1482, 1492), (1493, 1496), (1497, 1507), (1507, 1508), (1510, 1511), (1511, 1512), (1513, 1514), (1514, 1519), (1520, 1526), (1526, 1529), (1530, 1531), (1532, 1537), (1538, 1540), (1541, 1543), (1544, 1551), (1552, 1554), (1555, 1559), (1560, 1565), (1565, 1566), (1569, 1570), (1571, 1573), (1574, 1581), (1582, 1590), (1591, 1594), (1595, 1599), (1600, 1612), (1613, 1615), (1616, 1625), (1626, 1629), (1630, 1637), (1638, 1647), (1648, 1650), (1651, 1654), (1655, 1663), (1664, 1671), (1671, 1672), (1675, 1676), (1677, 1682), (1683, 1691), (0, 0)], [(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1146, 1148), (1148, 1151), (1151, 1152), (1153, 1155), (1156, 1168), (1168, 1169), (1170, 1174), (1175, 1179), (1180, 1182), (1182, 1183), (1183, 1186), (1187, 1190), (1190, 1193), (1193, 1197), (1198, 1204), (1204, 1205), (1206, 1210), (1211, 1213), (1214, 1218), (1219, 1223), (1224, 1227), (1228, 1237), (1237, 1238), (1240, 1241), (1241, 1242), (1243, 1246), (1246, 1249), (1250, 1253), (1254, 1259), (1260, 1269), (1270, 1273), (1274, 1279), (1280, 1284), (1285, 1287), (1288, 1289), (1290, 1295), (1295, 1296), (1296, 1297), (1298, 1306), (1306, 1307), (1310, 1311), (1312, 1317), (1318, 1323), (1323, 1324), (1324, 1326), (1326, 1327), (1327, 1330), (1330, 1331), (1331, 1334), (1335, 1341), (1342, 1344), (1345, 1346), (1347, 1352), (1353, 1355), (1356, 1360), (1360, 1361), (1364, 1365), (1366, 1370), (1371, 1372), (1373, 1379), (1380, 1385), (1386, 1393), (1394, 1395), (1395, 1396), (1396, 1397), (1397, 1398), (1398, 1399), (1399, 1400), (1400, 1401), (1401, 1402), (1402, 1403), (1403, 1405), (1405, 1407), (1408, 1417), (1417, 1418), (1419, 1421), (1422, 1426), (1426, 1427), (1430, 1431), (1432, 1435), (1435, 1436), (1436, 1442), (1443, 1447), (1448, 1451), (1452, 1457), (1458, 1467), (1468, 1471), (1472, 1480), (1480, 1481), (1482, 1492), (1493, 1496), (1497, 1507), (1507, 1508), (1510, 1511), (1511, 1512), (1513, 1514), (1514, 1519), (1520, 1526), (1526, 1529), (1530, 1531), (1532, 1537), (1538, 1540), (1541, 1543), (1544, 1551), (1552, 1554), (1555, 1559), (1560, 1565), (1565, 1566), (1569, 1570), (1571, 1573), (1574, 1581), (1582, 1590), (1591, 1594), (1595, 1599), (1600, 1612), (1613, 1615), (1616, 1625), (1626, 1629), (1630, 1637), (1638, 1647), (1648, 1650), (1651, 1654), (1655, 1663), (1664, 1671), (1671, 1672), (1675, 1676), (1677, 1682), (1683, 1691), (1691, 1692), (1693, 1696), (1697, 1704), (1705, 1707), (1708, 1720), (1721, 1723), (1724, 1732), (1732, 1733), (1736, 1737), (1738, 1743), (1744, 1749), (1750, 1753), (1754, 1756), (1757, 1761), (1762, 1775), (1776, 1778), (1779, 1782), (1783, 1790), (1791, 1794), (1795, 1800), (1801, 1812), (1812, 1813), (1815, 1816), (1817, 1829), (1830, 1832), (1833, 1839), (1840, 1842), (1843, 1846), (1847, 1852), (1853, 1857), (1858, 1865), (1866, 1870), (1871, 1879), (1880, 1889), (1890, 1891), (1892, 1895), (1895, 1896), (1897, 1898), (1898, 1899), (1899, 1900), (1900, 1902), (1902, 1904), (1905, 1908), (1909, 1912), (1912, 1915), (1915, 1916), (1916, 1919), (1920, 1921), (1922, 1926), (1927, 1928), (1929, 1932), (1932, 1933), (1933, 1937), (1938, 1949), (1950, 1957), (1958, 1962), (1962, 1963), (1964, 1966), (1966, 1967), (1967, 1968), (1969, 1984), (1985, 1987), (1988, 1993), (1994, 1998), (1999, 2005), (2006, 2010), (2011, 2014), (2015, 2021), (2022, 2029), (2030, 2034), (2035, 2038), (2039, 2041), (2041, 2048), (2049, 2053), (2054, 2057), (2058, 2063), (2063, 2064), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]], 'overflow_to_sample_mapping': [0, 0]}\n",
            "[0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_=inputs.pop(\"overflow_to_sample_mapping\")\n",
        "offsets=inputs.pop(\"offset_mapping\")\n",
        "print(offsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeobLTRkQ7Ha",
        "outputId": "7fefad5f-63fc-4c1f-86ee-870ab42f0c37"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1, 2), (3, 15), (15, 16), (17, 22), (23, 25), (26, 29), (30, 33), (34, 36), (36, 37), (39, 40), (41, 53), (54, 62), (63, 72), (73, 75), (76, 79), (79, 82), (82, 86), (87, 93), (94, 96), (97, 104), (105, 110), (111, 113), (114, 119), (120, 124), (125, 127), (128, 142), (142, 143), (144, 155), (156, 166), (166, 167), (168, 176), (177, 186), (186, 187), (188, 191), (191, 194), (194, 201), (201, 202), (203, 214), (214, 215), (216, 220), (221, 231), (232, 235), (236, 240), (241, 243), (244, 248), (249, 252), (253, 262), (262, 263), (264, 267), (268, 271), (272, 274), (275, 277), (278, 282), (283, 290), (290, 291), (291, 295), (296, 298), (298, 299), (300, 306), (307, 309), (310, 313), (314, 317), (318, 326), (326, 327), (329, 330), (331, 343), (344, 352), (353, 356), (356, 357), (358, 360), (361, 368), (369, 377), (378, 381), (382, 385), (386, 391), (392, 395), (395, 398), (398, 402), (403, 409), (410, 412), (413, 414), (415, 420), (421, 425), (425, 426), (427, 431), (431, 432), (432, 436), (437, 441), (442, 444), (445, 449), (450, 453), (454, 458), (458, 462), (463, 466), (467, 471), (472, 477), (478, 482), (483, 487), (488, 491), (492, 501), (502, 504), (505, 508), (509, 514), (515, 518), (518, 519), (520, 522), (523, 526), (527, 531), (532, 536), (536, 537), (538, 542), (543, 544), (544, 546), (546, 549), (550, 556), (557, 565), (566, 568), (569, 581), (582, 584), (585, 590), (591, 596), (596, 599), (599, 601), (602, 605), (606, 609), (610, 612), (613, 621), (622, 624), (625, 631), (632, 637), (638, 646), (647, 658), (658, 659), (661, 664), (665, 671), (672, 673), (674, 677), (678, 687), (687, 690), (690, 691), (693, 694), (694, 695), (696, 700), (700, 701), (701, 703), (703, 704), (704, 707), (708, 713), (713, 714), (714, 716), (716, 717), (717, 720), (720, 721), (721, 724), (725, 731), (731, 732), (735, 736), (737, 741), (742, 753), (754, 756), (757, 759), (759, 760), (761, 764), (765, 767), (767, 768), (769, 774), (774, 775), (778, 779), (780, 783), (784, 791), (792, 794), (795, 800), (801, 804), (805, 814), (815, 818), (819, 832), (832, 833), (836, 837), (838, 841), (842, 846), (846, 847), (847, 853), (854, 862), (862, 866), (867, 871), (872, 876), (877, 882), (883, 890), (891, 893), (894, 899), (899, 900), (903, 904), (905, 906), (907, 914), (915, 918), (919, 922), (923, 928), (929, 932), (933, 936), (937, 940), (940, 943), (943, 947), (948, 954), (954, 955), (958, 959), (960, 965), (966, 969), (969, 973), (974, 979), (979, 980), (981, 988), (989, 995), (996, 1000), (1000, 1005), (1005, 1006), (1008, 1009), (1009, 1010), (1011, 1022), (1023, 1026), (1027, 1032), (1033, 1040), (1041, 1047), (1048, 1055), (1056, 1058), (1059, 1065), (1066, 1068), (1068, 1071), (1071, 1076), (1076, 1077), (1080, 1081), (1082, 1083), (1083, 1086), (1086, 1088), (1088, 1092), (1092, 1095), (1096, 1099), (1100, 1106), (1107, 1110), (1110, 1114), (1115, 1119), (1120, 1123), (1124, 1134), (1135, 1140), (1140, 1141), (1144, 1145), (1146, 1148), (1148, 1151), (1151, 1152), (1153, 1155), (1156, 1168), (1168, 1169), (1170, 1174), (1175, 1179), (1180, 1182), (1182, 1183), (1183, 1186), (1187, 1190), (1190, 1193), (1193, 1197), (1198, 1204), (1204, 1205), (1206, 1210), (1211, 1213), (1214, 1218), (1219, 1223), (1224, 1227), (1228, 1237), (1237, 1238), (1240, 1241), (1241, 1242), (1243, 1246), (1246, 1249), (1250, 1253), (1254, 1259), (1260, 1269), (1270, 1273), (1274, 1279), (1280, 1284), (1285, 1287), (1288, 1289), (1290, 1295), (1295, 1296), (1296, 1297), (1298, 1306), (1306, 1307), (1310, 1311), (1312, 1317), (1318, 1323), (1323, 1324), (1324, 1326), (1326, 1327), (1327, 1330), (1330, 1331), (1331, 1334), (1335, 1341), (1342, 1344), (1345, 1346), (1347, 1352), (1353, 1355), (1356, 1360), (1360, 1361), (1364, 1365), (1366, 1370), (1371, 1372), (1373, 1379), (1380, 1385), (1386, 1393), (1394, 1395), (1395, 1396), (1396, 1397), (1397, 1398), (1398, 1399), (1399, 1400), (1400, 1401), (1401, 1402), (1402, 1403), (1403, 1405), (1405, 1407), (1408, 1417), (1417, 1418), (1419, 1421), (1422, 1426), (1426, 1427), (1430, 1431), (1432, 1435), (1435, 1436), (1436, 1442), (1443, 1447), (1448, 1451), (1452, 1457), (1458, 1467), (1468, 1471), (1472, 1480), (1480, 1481), (1482, 1492), (1493, 1496), (1497, 1507), (1507, 1508), (1510, 1511), (1511, 1512), (1513, 1514), (1514, 1519), (1520, 1526), (1526, 1529), (1530, 1531), (1532, 1537), (1538, 1540), (1541, 1543), (1544, 1551), (1552, 1554), (1555, 1559), (1560, 1565), (1565, 1566), (1569, 1570), (1571, 1573), (1574, 1581), (1582, 1590), (1591, 1594), (1595, 1599), (1600, 1612), (1613, 1615), (1616, 1625), (1626, 1629), (1630, 1637), (1638, 1647), (1648, 1650), (1651, 1654), (1655, 1663), (1664, 1671), (1671, 1672), (1675, 1676), (1677, 1682), (1683, 1691), (0, 0)], [(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1146, 1148), (1148, 1151), (1151, 1152), (1153, 1155), (1156, 1168), (1168, 1169), (1170, 1174), (1175, 1179), (1180, 1182), (1182, 1183), (1183, 1186), (1187, 1190), (1190, 1193), (1193, 1197), (1198, 1204), (1204, 1205), (1206, 1210), (1211, 1213), (1214, 1218), (1219, 1223), (1224, 1227), (1228, 1237), (1237, 1238), (1240, 1241), (1241, 1242), (1243, 1246), (1246, 1249), (1250, 1253), (1254, 1259), (1260, 1269), (1270, 1273), (1274, 1279), (1280, 1284), (1285, 1287), (1288, 1289), (1290, 1295), (1295, 1296), (1296, 1297), (1298, 1306), (1306, 1307), (1310, 1311), (1312, 1317), (1318, 1323), (1323, 1324), (1324, 1326), (1326, 1327), (1327, 1330), (1330, 1331), (1331, 1334), (1335, 1341), (1342, 1344), (1345, 1346), (1347, 1352), (1353, 1355), (1356, 1360), (1360, 1361), (1364, 1365), (1366, 1370), (1371, 1372), (1373, 1379), (1380, 1385), (1386, 1393), (1394, 1395), (1395, 1396), (1396, 1397), (1397, 1398), (1398, 1399), (1399, 1400), (1400, 1401), (1401, 1402), (1402, 1403), (1403, 1405), (1405, 1407), (1408, 1417), (1417, 1418), (1419, 1421), (1422, 1426), (1426, 1427), (1430, 1431), (1432, 1435), (1435, 1436), (1436, 1442), (1443, 1447), (1448, 1451), (1452, 1457), (1458, 1467), (1468, 1471), (1472, 1480), (1480, 1481), (1482, 1492), (1493, 1496), (1497, 1507), (1507, 1508), (1510, 1511), (1511, 1512), (1513, 1514), (1514, 1519), (1520, 1526), (1526, 1529), (1530, 1531), (1532, 1537), (1538, 1540), (1541, 1543), (1544, 1551), (1552, 1554), (1555, 1559), (1560, 1565), (1565, 1566), (1569, 1570), (1571, 1573), (1574, 1581), (1582, 1590), (1591, 1594), (1595, 1599), (1600, 1612), (1613, 1615), (1616, 1625), (1626, 1629), (1630, 1637), (1638, 1647), (1648, 1650), (1651, 1654), (1655, 1663), (1664, 1671), (1671, 1672), (1675, 1676), (1677, 1682), (1683, 1691), (1691, 1692), (1693, 1696), (1697, 1704), (1705, 1707), (1708, 1720), (1721, 1723), (1724, 1732), (1732, 1733), (1736, 1737), (1738, 1743), (1744, 1749), (1750, 1753), (1754, 1756), (1757, 1761), (1762, 1775), (1776, 1778), (1779, 1782), (1783, 1790), (1791, 1794), (1795, 1800), (1801, 1812), (1812, 1813), (1815, 1816), (1817, 1829), (1830, 1832), (1833, 1839), (1840, 1842), (1843, 1846), (1847, 1852), (1853, 1857), (1858, 1865), (1866, 1870), (1871, 1879), (1880, 1889), (1890, 1891), (1892, 1895), (1895, 1896), (1897, 1898), (1898, 1899), (1899, 1900), (1900, 1902), (1902, 1904), (1905, 1908), (1909, 1912), (1912, 1915), (1915, 1916), (1916, 1919), (1920, 1921), (1922, 1926), (1927, 1928), (1929, 1932), (1932, 1933), (1933, 1937), (1938, 1949), (1950, 1957), (1958, 1962), (1962, 1963), (1964, 1966), (1966, 1967), (1967, 1968), (1969, 1984), (1985, 1987), (1988, 1993), (1994, 1998), (1999, 2005), (2006, 2010), (2011, 2014), (2015, 2021), (2022, 2029), (2030, 2034), (2035, 2038), (2039, 2041), (2041, 2048), (2049, 2053), (2054, 2057), (2058, 2063), (2063, 2064), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=inputs.convert_to_tensors(\"pt\")\n",
        "print(inputs)\n",
        "\n",
        "print(inputs[\"input_ids\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x3bW2OiSXyk",
        "outputId": "fbf4fc8d-56ca-4bd7-8efb-4bbb448a6060"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  5979,  1996,  3776,  9818,  1171,   100, 25267,   136,   102,\n",
            "           100, 25267,   131,  1426,  1104,  1103,  2051, 21239,  2101,   100,\n",
            "         25267,  2790,  4674,  1104,  3073,  4487,  9044,  3584,  1106,  3870,\n",
            "          8249,  1113,  6685,  1216,  1112,  5393,   117,  1869, 16026,   117,\n",
            "          2304, 10937,   117,  7584,  7317,  2734,   117,  5179,   117,  3087,\n",
            "          3964,  1105,  1167,  1107,  1166,  1620,  3483,   119,  2098,  6457,\n",
            "          1110,  1106,  1294,  5910,   118,  2652, 21239,  2101,  5477,  1106,\n",
            "          1329,  1111,  2490,   119,   100, 25267,  2790, 20480,  1116,  1106,\n",
            "          1976,  9133,  1105,  1329,  1343,  3073,  4487,  9044,  3584,  1113,\n",
            "           170,  1549,  3087,   117,  2503,   118,  9253,  1172,  1113,  1240,\n",
            "          1319,  2233, 27948,  1105,  1173,  2934,  1172,  1114,  1103,  1661,\n",
            "          1113,  1412,  2235, 10960,   119,  1335,  1103,  1269,  1159,   117,\n",
            "          1296,   185, 25669,  8613, 13196, 13682,  1126,  4220,  1110,  3106,\n",
            "          2484, 20717,  1673,  1105,  1169,  1129,  5847,  1106,  9396,  3613,\n",
            "          1844,  7857,   119,  2009,  1431,   146,  1329, 11303,  1468,   136,\n",
            "           122,   119, 12167,   118,  1106,   118,  1329,  1352,   118,  1104,\n",
            "           118,  1103,   118,  1893,  3584,   131,   118,  1693,  2099,  1113,\n",
            "         21239,  2591,  1105, 21239,  2349,  8249,   119,   118,  8274,  9391,\n",
            "          1106,  3990,  1111, 24937,  1105, 16681,   119,   118, 17751,  4795,\n",
            "           118,  4749, 11108,  5266,  1114,  1198,  1210,  3553,  1106,  3858,\n",
            "           119,   118,   138, 13943, 20480,  1111,  1606,  1155,  1412,  3073,\n",
            "          4487,  9044,  3584,   119,   118,  5738,  3254, 22662,  4692,   117,\n",
            "          2964,  6302,  2555, 10988,   131,   123,   119, 26982,  1169,  2934,\n",
            "          3972,  3584,  1939,  1104,  1579,  1231,  4487, 16534,   119,   118,\n",
            "           153, 19366,  3121,  2116,  1468,  1169,  4851,  3254, 22662,  1159,\n",
            "          1105,  1707,  4692,   119,   118,  2091, 10947,  1116,  1104,  4220,\n",
            "          1116,  1114,  1166,  1275,   117,  1288,  3073,  4487,  9044,  3584,\n",
            "           117,  1199,  1107,  1167,  1190,  1620,  3483,   119,   124,   119,\n",
            "         22964,  6787,  1103,  1268,  8297,  1111,  1451,  1226,  1104,   170,\n",
            "          2235,   112,   188,  7218,   131,   118,  9791,  1352,   118,  1104,\n",
            "           118,  1103,   118,  1893,  3584,  1107,   124,  2442,  1104,  3463,\n",
            "           119,   118, 15729,   170,  1423,  2235,  1206,   157,  2271,  1477,\n",
            "           119,   121,   120,   153,  1183,  1942,  1766,  1732,  8297,  1116,\n",
            "          1120,  1209,   119,   118,  3017,  1306,  8709,  3368,  1103,  1268,\n",
            "          8297,  1111,  2013,   117, 10540,  1105,  1707,   119,   125,   119,\n",
            "           142, 20158,  8156,  3708,   170,  2235,  1137,  1126,  1859,  1106,\n",
            "          1240,  2993,   131,   118,  1284,  2194,  5136,  1111,  1296,  4220,\n",
            "          1106, 23577,  1103,  2686,  1502,  1118,  1157,  1560,  5752,   119,\n",
            "           118,  6747,  4422,   102],\n",
            "        [  101,  5979,  1996,  3776,  9818,  1171,   100, 25267,   136,   102,\n",
            "          2091, 10947,  1116,  1104,  4220,  1116,  1114,  1166,  1275,   117,\n",
            "          1288,  3073,  4487,  9044,  3584,   117,  1199,  1107,  1167,  1190,\n",
            "          1620,  3483,   119,   124,   119, 22964,  6787,  1103,  1268,  8297,\n",
            "          1111,  1451,  1226,  1104,   170,  2235,   112,   188,  7218,   131,\n",
            "           118,  9791,  1352,   118,  1104,   118,  1103,   118,  1893,  3584,\n",
            "          1107,   124,  2442,  1104,  3463,   119,   118, 15729,   170,  1423,\n",
            "          2235,  1206,   157,  2271,  1477,   119,   121,   120,   153,  1183,\n",
            "          1942,  1766,  1732,  8297,  1116,  1120,  1209,   119,   118,  3017,\n",
            "          1306,  8709,  3368,  1103,  1268,  8297,  1111,  2013,   117, 10540,\n",
            "          1105,  1707,   119,   125,   119,   142, 20158,  8156,  3708,   170,\n",
            "          2235,  1137,  1126,  1859,  1106,  1240,  2993,   131,   118,  1284,\n",
            "          2194,  5136,  1111,  1296,  4220,  1106, 23577,  1103,  2686,  1502,\n",
            "          1118,  1157,  1560,  5752,   119,   118,  6747,  4422,  1116,  1132,\n",
            "          5490,  1112, 10887,  1112,  1936,   119,   118,  6747,  7004,  1169,\n",
            "          1129,  1215,  8942,  1104,  1103,  3340,  1111,  3613,  7857,   119,\n",
            "           100, 25267,  1110,  5534,  1118,  1103,  1210,  1211,  1927,  1996,\n",
            "          3776,  9818,   783, 13612,   117,   153,  1183,  1942,  1766,  1732,\n",
            "          1105,  5157, 21484,  2271,  6737,   783,  1114,   170,  2343,  1306,\n",
            "          2008,  9111,  1206,  1172,   119,  1135,   112,   188, 21546,  1106,\n",
            "          2669,  1240,  3584,  1114,  1141,  1196, 10745,  1172,  1111,  1107,\n",
            "         16792,  1114,  1103,  1168,   119,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "torch.Size([2, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "start_logits=outputs.start_logits\n",
        "end_logits=outputs.end_logits\n",
        "\n",
        "print(start_logits.shape, end_logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJBlLSgsSzjX",
        "outputId": "f03abd94-dd60-4799-f8b4-453d55686797"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 384]) torch.Size([2, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_ids = inputs.sequence_ids()\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "mask[0] = False\n",
        "mask=torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] ==0))\n",
        "\n",
        "start_logits[mask] = -1000\n",
        "end_logits[mask] = -1000"
      ],
      "metadata": {
        "id": "RsHOPBkeTfjN"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)"
      ],
      "metadata": {
        "id": "wp-0bWC_lXus"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates= []\n",
        "\n",
        "for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n",
        "  scores = start_probs[:, None] * end_probs[None, :]\n",
        "  idx = torch.triu(scores).argmax().item()\n",
        "\n",
        "  start_idx=idx // scores.shape[1]\n",
        "  end_idx=idx % scores.shape[1]\n",
        "  score=scores[start_idx, end_idx].item()\n",
        "  candidates.append((start_idx, end_idx, score))\n",
        "\n",
        "print(candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFup9gPAllEm",
        "outputId": "4498e418-de77-4257-f3a9-8daab80715aa"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 18, 0.3386707305908203), (173, 184, 0.9714868664741516)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for candidate, offset in zip(candidates, offsets):\n",
        "  start_token, end_token, score = candidate\n",
        "  start_char,_=offset[start_token]\n",
        "  _, end_char = offset[end_token]\n",
        "  answer = long_context[start_char:end_char]\n",
        "  result = {\"answer\": answer,\"start\": start_char, \"end\": end_char, \"score\": score}\n",
        "  print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzZ_HXXPnK1i",
        "outputId": "d8d96684-0392-4fec-fee5-186f83cb5eb0"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer': '\\nðŸ¤— Transformers: State of the Art NLP', 'start': 0, 'end': 37, 'score': 0.3386707305908203}\n",
            "{'answer': 'Jax, PyTorch and TensorFlow', 'start': 1892, 'end': 1919, 'score': 0.9714868664741516}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PSgOeRKoNJh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}